{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "from sys import stdout\n",
    "#sys.path.append(path+'/src/python/')\n",
    "from time import time\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from seaborn.linearmodels import *\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred)) \n",
    "\n",
    "path = './data/'\n",
    "train_file = path + 'train.csv'\n",
    "test_file = path + 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.drop(train_df[train_df[\"GrLivArea\"] > 4000].index, inplace=True)\n",
    "\n",
    "test_df.loc[666, \"GarageQual\"] = \"TA\"\n",
    "test_df.loc[666, \"GarageCond\"] = \"TA\"\n",
    "test_df.loc[666, \"GarageFinish\"] = \"Unf\"\n",
    "test_df.loc[666, \"GarageYrBlt\"] = \"1980\"\n",
    "\n",
    "test_df.loc[1116, \"GarageType\"] = np.nan\n",
    "\n",
    "lot_frontage_by_neighborhood = train_df[\"LotFrontage\"].groupby(train_df[\"Neighborhood\"])\n",
    "\n",
    "# Used to convert categorical features into ordinal numbers.\n",
    "# (There's probably an easier way to do this, but it works.)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "def factorize(df, factor_df, column, fill_na=None):\n",
    "    factor_df[column] = df[column]\n",
    "    if fill_na is not None:\n",
    "        factor_df[column].fillna(fill_na, inplace=True)\n",
    "    le.fit(factor_df[column].unique())\n",
    "    factor_df[column] = le.transform(factor_df[column])\n",
    "    return factor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 111)\n",
      "(1459, 111)\n"
     ]
    }
   ],
   "source": [
    "# Combine all the (numerical) features into one big DataFrame. We don't add \n",
    "# the one-hot encoded variables here yet, that happens later on.\n",
    "def munge(df):\n",
    "    all_df = pd.DataFrame(index = df.index)\n",
    "   \n",
    "    all_df[\"LotFrontage\"] = df[\"LotFrontage\"]   \n",
    "    for key, group in lot_frontage_by_neighborhood:\n",
    "        idx = (df[\"Neighborhood\"] == key) & (df[\"LotFrontage\"].isnull())\n",
    "        all_df.loc[idx, \"LotFrontage\"] = group.median()    \n",
    "\n",
    "    all_df[\"LotArea\"] = df[\"LotArea\"]\n",
    "\n",
    "    all_df[\"MasVnrArea\"] = df[\"MasVnrArea\"]\n",
    "    all_df[\"MasVnrArea\"].fillna(0, inplace=True)\n",
    "   \n",
    "    all_df[\"BsmtFinSF1\"] = df[\"BsmtFinSF1\"]\n",
    "    all_df[\"BsmtFinSF1\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"BsmtFinSF2\"] = df[\"BsmtFinSF2\"]\n",
    "    all_df[\"BsmtFinSF2\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"BsmtUnfSF\"] = df[\"BsmtUnfSF\"]\n",
    "    all_df[\"BsmtUnfSF\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"TotalBsmtSF\"] = df[\"TotalBsmtSF\"]\n",
    "    all_df[\"TotalBsmtSF\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"1stFlrSF\"] = df[\"1stFlrSF\"]\n",
    "    all_df[\"2ndFlrSF\"] = df[\"2ndFlrSF\"]\n",
    "    all_df[\"GrLivArea\"] = df[\"GrLivArea\"]\n",
    "    \n",
    "    all_df[\"GarageArea\"] = df[\"GarageArea\"]\n",
    "    all_df[\"GarageArea\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"WoodDeckSF\"] = df[\"WoodDeckSF\"]\n",
    "    all_df[\"OpenPorchSF\"] = df[\"OpenPorchSF\"]\n",
    "    all_df[\"EnclosedPorch\"] = df[\"EnclosedPorch\"]\n",
    "    all_df[\"3SsnPorch\"] = df[\"3SsnPorch\"]\n",
    "    all_df[\"ScreenPorch\"] = df[\"ScreenPorch\"]\n",
    "    \n",
    "    all_df[\"BsmtFullBath\"] = df[\"BsmtFullBath\"]\n",
    "    all_df[\"BsmtFullBath\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"BsmtHalfBath\"] = df[\"BsmtHalfBath\"]\n",
    "    all_df[\"BsmtHalfBath\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"FullBath\"] = df[\"FullBath\"] \n",
    "    all_df[\"HalfBath\"] = df[\"HalfBath\"] \n",
    "    all_df[\"BedroomAbvGr\"] = df[\"BedroomAbvGr\"] \n",
    "    all_df[\"KitchenAbvGr\"] = df[\"KitchenAbvGr\"] \n",
    "    all_df[\"TotRmsAbvGrd\"] = df[\"TotRmsAbvGrd\"] \n",
    "    all_df[\"Fireplaces\"] = df[\"Fireplaces\"] \n",
    "\n",
    "    all_df[\"GarageCars\"] = df[\"GarageCars\"]\n",
    "    all_df[\"GarageCars\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"CentralAir\"] = (df[\"CentralAir\"] == \"Y\") * 1.0\n",
    "   \n",
    "    all_df[\"OverallQual\"] = df[\"OverallQual\"]\n",
    "    all_df[\"OverallCond\"] = df[\"OverallCond\"]\n",
    "\n",
    "    # Quality measurements are stored as text but we can convert them to \n",
    "    # numbers where a higher number means higher quality.\n",
    "\n",
    "    qual_dict = {None: 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n",
    "    all_df[\"ExterQual\"] = df[\"ExterQual\"].map(qual_dict).astype(int)\n",
    "    all_df[\"ExterCond\"] = df[\"ExterCond\"].map(qual_dict).astype(int)\n",
    "    all_df[\"BsmtQual\"] = df[\"BsmtQual\"].map(qual_dict).astype(int)\n",
    "    all_df[\"BsmtCond\"] = df[\"BsmtCond\"].map(qual_dict).astype(int)\n",
    "    all_df[\"HeatingQC\"] = df[\"HeatingQC\"].map(qual_dict).astype(int)\n",
    "    all_df[\"KitchenQual\"] = df[\"KitchenQual\"].map(qual_dict).astype(int)\n",
    "    all_df[\"FireplaceQu\"] = df[\"FireplaceQu\"].map(qual_dict).astype(int)\n",
    "    all_df[\"GarageQual\"] = df[\"GarageQual\"].map(qual_dict).astype(int)\n",
    "    all_df[\"GarageCond\"] = df[\"GarageCond\"].map(qual_dict).astype(int)\n",
    "\n",
    "    all_df[\"BsmtExposure\"] = df[\"BsmtExposure\"].map(\n",
    "        {None: 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}).astype(int)\n",
    "\n",
    "    bsmt_fin_dict = {None: 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6}\n",
    "    all_df[\"BsmtFinType1\"] = df[\"BsmtFinType1\"].map(bsmt_fin_dict).astype(int)\n",
    "    all_df[\"BsmtFinType2\"] = df[\"BsmtFinType2\"].map(bsmt_fin_dict).astype(int)\n",
    "\n",
    "    all_df[\"Functional\"] = df[\"Functional\"].map(\n",
    "        {None: 0, \"Sal\": 1, \"Sev\": 2, \"Maj2\": 3, \"Maj1\": 4, \n",
    "         \"Mod\": 5, \"Min2\": 6, \"Min1\": 7, \"Typ\": 8}).astype(int)\n",
    "\n",
    "    all_df[\"GarageFinish\"] = df[\"GarageFinish\"].map(\n",
    "        {None: 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3}).astype(int)\n",
    "\n",
    "    all_df[\"Fence\"] = df[\"Fence\"].map(\n",
    "        {None: 0, \"MnWw\": 1, \"GdWo\": 2, \"MnPrv\": 3, \"GdPrv\": 4}).astype(int)\n",
    "\n",
    "    all_df[\"YearBuilt\"] = df[\"YearBuilt\"]\n",
    "    all_df[\"YearRemodAdd\"] = df[\"YearRemodAdd\"]\n",
    "\n",
    "    all_df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"]\n",
    "    all_df[\"GarageYrBlt\"].fillna(0.0, inplace=True)\n",
    "\n",
    "    all_df[\"MoSold\"] = df[\"MoSold\"]\n",
    "    all_df[\"YrSold\"] = df[\"YrSold\"]\n",
    "    \n",
    "    all_df[\"LowQualFinSF\"] = df[\"LowQualFinSF\"]\n",
    "    all_df[\"MiscVal\"] = df[\"MiscVal\"]\n",
    "\n",
    "    all_df[\"PoolQC\"] = df[\"PoolQC\"].map(qual_dict).astype(int)\n",
    "\n",
    "    all_df[\"PoolArea\"] = df[\"PoolArea\"]\n",
    "    all_df[\"PoolArea\"].fillna(0, inplace=True)\n",
    "    \n",
    "    # Add categorical features as numbers too. It seems to help a bit.\n",
    "    all_df = factorize(df, all_df, \"MSSubClass\")\n",
    "    all_df = factorize(df, all_df, \"MSZoning\", \"RL\")\n",
    "    all_df = factorize(df, all_df, \"LotConfig\")\n",
    "    all_df = factorize(df, all_df, \"Neighborhood\")\n",
    "    all_df = factorize(df, all_df, \"Condition1\")\n",
    "    all_df = factorize(df, all_df, \"BldgType\")\n",
    "    all_df = factorize(df, all_df, \"HouseStyle\")\n",
    "    all_df = factorize(df, all_df, \"RoofStyle\")\n",
    "    all_df = factorize(df, all_df, \"Exterior1st\", \"Other\")\n",
    "    all_df = factorize(df, all_df, \"Exterior2nd\", \"Other\")\n",
    "    all_df = factorize(df, all_df, \"MasVnrType\", \"None\")\n",
    "    all_df = factorize(df, all_df, \"Foundation\")\n",
    "    all_df = factorize(df, all_df, \"SaleType\", \"Oth\")\n",
    "    all_df = factorize(df, all_df, \"SaleCondition\")\n",
    "\n",
    "    # IR2 and IR3 don't appear that often, so just make a distinction\n",
    "    # between regular and irregular.\n",
    "    all_df[\"IsRegularLotShape\"] = (df[\"LotShape\"] == \"Reg\") * 1\n",
    "\n",
    "    # Most properties are level; bin the other possibilities together\n",
    "    # as \"not level\".\n",
    "    all_df[\"IsLandLevel\"] = (df[\"LandContour\"] == \"Lvl\") * 1\n",
    "\n",
    "    # Most land slopes are gentle; treat the others as \"not gentle\".\n",
    "    all_df[\"IsLandSlopeGentle\"] = (df[\"LandSlope\"] == \"Gtl\") * 1\n",
    "\n",
    "    # Most properties use standard circuit breakers.\n",
    "    all_df[\"IsElectricalSBrkr\"] = (df[\"Electrical\"] == \"SBrkr\") * 1\n",
    "\n",
    "    # About 2/3rd have an attached garage.\n",
    "    all_df[\"IsGarageDetached\"] = (df[\"GarageType\"] == \"Detchd\") * 1\n",
    "\n",
    "    # Most have a paved drive. Treat dirt/gravel and partial pavement\n",
    "    # as \"not paved\".\n",
    "    all_df[\"IsPavedDrive\"] = (df[\"PavedDrive\"] == \"Y\") * 1\n",
    "\n",
    "    # The only interesting \"misc. feature\" is the presence of a shed.\n",
    "    all_df[\"HasShed\"] = (df[\"MiscFeature\"] == \"Shed\") * 1.  \n",
    "\n",
    "    # If YearRemodAdd != YearBuilt, then a remodeling took place at some point.\n",
    "    all_df[\"Remodeled\"] = (all_df[\"YearRemodAdd\"] != all_df[\"YearBuilt\"]) * 1\n",
    "    \n",
    "    # Did a remodeling happen in the year the house was sold?\n",
    "    all_df[\"RecentRemodel\"] = (all_df[\"YearRemodAdd\"] == all_df[\"YrSold\"]) * 1\n",
    "    \n",
    "    # Was this house sold in the year it was built?\n",
    "    all_df[\"VeryNewHouse\"] = (all_df[\"YearBuilt\"] == all_df[\"YrSold\"]) * 1\n",
    "\n",
    "    all_df[\"Has2ndFloor\"] = (all_df[\"2ndFlrSF\"] == 0) * 1\n",
    "    all_df[\"HasMasVnr\"] = (all_df[\"MasVnrArea\"] == 0) * 1\n",
    "    all_df[\"HasWoodDeck\"] = (all_df[\"WoodDeckSF\"] == 0) * 1\n",
    "    all_df[\"HasOpenPorch\"] = (all_df[\"OpenPorchSF\"] == 0) * 1\n",
    "    all_df[\"HasEnclosedPorch\"] = (all_df[\"EnclosedPorch\"] == 0) * 1\n",
    "    all_df[\"Has3SsnPorch\"] = (all_df[\"3SsnPorch\"] == 0) * 1\n",
    "    all_df[\"HasScreenPorch\"] = (all_df[\"ScreenPorch\"] == 0) * 1\n",
    "\n",
    "    # These features actually lower the score a little.\n",
    "    # all_df[\"HasBasement\"] = df[\"BsmtQual\"].isnull() * 1\n",
    "    # all_df[\"HasGarage\"] = df[\"GarageQual\"].isnull() * 1\n",
    "    # all_df[\"HasFireplace\"] = df[\"FireplaceQu\"].isnull() * 1\n",
    "    # all_df[\"HasFence\"] = df[\"Fence\"].isnull() * 1\n",
    "\n",
    "    # Months with the largest number of deals may be significant.\n",
    "    all_df[\"HighSeason\"] = df[\"MoSold\"].replace( \n",
    "        {1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0})\n",
    "\n",
    "    all_df[\"NewerDwelling\"] = df[\"MSSubClass\"].replace(\n",
    "        {20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1, 70: 0, 75: 0, 80: 0, 85: 0,\n",
    "         90: 0, 120: 1, 150: 0, 160: 0, 180: 0, 190: 0})   \n",
    "    \n",
    "    all_df.loc[df.Neighborhood == 'NridgHt', \"Neighborhood_Good\"] = 1\n",
    "    all_df.loc[df.Neighborhood == 'Crawfor', \"Neighborhood_Good\"] = 1\n",
    "    all_df.loc[df.Neighborhood == 'StoneBr', \"Neighborhood_Good\"] = 1\n",
    "    all_df.loc[df.Neighborhood == 'Somerst', \"Neighborhood_Good\"] = 1\n",
    "    all_df.loc[df.Neighborhood == 'NoRidge', \"Neighborhood_Good\"] = 1\n",
    "    all_df[\"Neighborhood_Good\"].fillna(0, inplace=True)\n",
    "\n",
    "    all_df[\"SaleCondition_PriceDown\"] = df.SaleCondition.replace(\n",
    "        {'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0})\n",
    "\n",
    "    # House completed before sale or not\n",
    "    all_df[\"BoughtOffPlan\"] = df.SaleCondition.replace(\n",
    "        {\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "    \n",
    "    all_df[\"BadHeating\"] = df.HeatingQC.replace(\n",
    "        {'Ex': 0, 'Gd': 0, 'TA': 0, 'Fa': 1, 'Po': 1})\n",
    "\n",
    "    area_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', \n",
    "                 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'LowQualFinSF', 'PoolArea' ]\n",
    "    all_df[\"TotalArea\"] = all_df[area_cols].sum(axis=1)\n",
    "\n",
    "    all_df[\"TotalArea1st2nd\"] = all_df[\"1stFlrSF\"] + all_df[\"2ndFlrSF\"]\n",
    "\n",
    "    all_df[\"Age\"] = 2010 - all_df[\"YearBuilt\"]\n",
    "    all_df[\"TimeSinceSold\"] = 2010 - all_df[\"YrSold\"]\n",
    "\n",
    "    all_df[\"SeasonSold\"] = all_df[\"MoSold\"].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, \n",
    "                                                  6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\n",
    "    \n",
    "    all_df[\"YearsSinceRemodel\"] = all_df[\"YrSold\"] - all_df[\"YearRemodAdd\"]\n",
    "    \n",
    "    # Simplifications of existing features into bad/average/good.\n",
    "    all_df[\"SimplOverallQual\"] = all_df.OverallQual.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n",
    "    all_df[\"SimplOverallCond\"] = all_df.OverallCond.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n",
    "    all_df[\"SimplPoolQC\"] = all_df.PoolQC.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 2, 4 : 2})\n",
    "    all_df[\"SimplGarageCond\"] = all_df.GarageCond.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplGarageQual\"] = all_df.GarageQual.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplFireplaceQu\"] = all_df.FireplaceQu.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplFireplaceQu\"] = all_df.FireplaceQu.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplFunctional\"] = all_df.Functional.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 2, 4 : 2, 5 : 3, 6 : 3, 7 : 3, 8 : 4})\n",
    "    all_df[\"SimplKitchenQual\"] = all_df.KitchenQual.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplHeatingQC\"] = all_df.HeatingQC.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplBsmtFinType1\"] = all_df.BsmtFinType1.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n",
    "    all_df[\"SimplBsmtFinType2\"] = all_df.BsmtFinType2.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n",
    "    all_df[\"SimplBsmtCond\"] = all_df.BsmtCond.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplBsmtQual\"] = all_df.BsmtQual.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplExterCond\"] = all_df.ExterCond.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "    all_df[\"SimplExterQual\"] = all_df.ExterQual.replace(\n",
    "        {1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "            \n",
    "    # Bin by neighborhood (a little arbitrarily). Values were computed by: \n",
    "    # train_df[\"SalePrice\"].groupby(train_df[\"Neighborhood\"]).median().sort_values()\n",
    "    neighborhood_map = {\n",
    "        \"MeadowV\" : 0,  #  88000\n",
    "        \"IDOTRR\" : 1,   # 103000\n",
    "        \"BrDale\" : 1,   # 106000\n",
    "        \"OldTown\" : 1,  # 119000\n",
    "        \"Edwards\" : 1,  # 119500\n",
    "        \"BrkSide\" : 1,  # 124300\n",
    "        \"Sawyer\" : 1,   # 135000\n",
    "        \"Blueste\" : 1,  # 137500\n",
    "        \"SWISU\" : 2,    # 139500\n",
    "        \"NAmes\" : 2,    # 140000\n",
    "        \"NPkVill\" : 2,  # 146000\n",
    "        \"Mitchel\" : 2,  # 153500\n",
    "        \"SawyerW\" : 2,  # 179900\n",
    "        \"Gilbert\" : 2,  # 181000\n",
    "        \"NWAmes\" : 2,   # 182900\n",
    "        \"Blmngtn\" : 2,  # 191000\n",
    "        \"CollgCr\" : 2,  # 197200\n",
    "        \"ClearCr\" : 3,  # 200250\n",
    "        \"Crawfor\" : 3,  # 200624\n",
    "        \"Veenker\" : 3,  # 218000\n",
    "        \"Somerst\" : 3,  # 225500\n",
    "        \"Timber\" : 3,   # 228475\n",
    "        \"StoneBr\" : 4,  # 278000\n",
    "        \"NoRidge\" : 4,  # 290000\n",
    "        \"NridgHt\" : 4,  # 315000\n",
    "    }\n",
    "\n",
    "    all_df[\"NeighborhoodBin\"] = df[\"Neighborhood\"].map(neighborhood_map)\n",
    "    return all_df\n",
    "\n",
    "train_df_munged = munge(train_df)\n",
    "test_df_munged = munge(test_df)\n",
    "\n",
    "print(train_df_munged.shape)\n",
    "print(test_df_munged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy NeighborhoodBin into a temporary DataFrame because we want to use the\n",
    "# unscaled version later on (to one-hot encode it). \n",
    "neighborhood_bin_train = pd.DataFrame(index = train_df.index)\n",
    "neighborhood_bin_train[\"NeighborhoodBin\"] = train_df_munged[\"NeighborhoodBin\"]\n",
    "neighborhood_bin_test = pd.DataFrame(index = test_df.index)\n",
    "neighborhood_bin_test[\"NeighborhoodBin\"] = test_df_munged[\"NeighborhoodBin\"]\n",
    "\n",
    "################################################################################\n",
    "\n",
    "numeric_features = train_df_munged.dtypes[train_df_munged.dtypes != \"object\"].index\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1456, 111)\n",
      "Test set size: (1459, 111)\n"
     ]
    }
   ],
   "source": [
    "# Transform the skewed features by taking log(feature + 1).\n",
    "# This will make the features more normal.\n",
    "from scipy.stats import skew\n",
    "\n",
    "skewed = train_df_munged.apply(lambda x: skew(x.dropna().astype(float)))\n",
    "skewed = skewed[skewed > 0.75]\n",
    "skewed = skewed.index\n",
    "\n",
    "train_df_munged[skewed] = np.log1p(train_df_munged[skewed])\n",
    "test_df_munged[skewed] = np.log1p(test_df_munged[skewed])\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# We take the log here because the error metric is between the log of the\n",
    "# SalePrice and the log of the predicted price. That does mean we need to \n",
    "# exp() the prediction to get an actual sale price.\n",
    "label_df = pd.DataFrame(index = train_df_munged.index, columns=[\"SalePrice\"])\n",
    "label_df[\"SalePrice\"] = np.log(train_df[\"SalePrice\"])\n",
    "\n",
    "print(\"Training set size:\", train_df_munged.shape)\n",
    "print(\"Test set size:\", test_df_munged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features : 38\n",
      "Categorical features : 43\n"
     ]
    }
   ],
   "source": [
    "categorical_features = train_df.select_dtypes(include = [\"object\"]).columns\n",
    "numerical_features = train_df.select_dtypes(exclude = [\"object\"]).columns\n",
    "print(\"Numerical features : \" + str(len(numerical_features)))\n",
    "print(\"Categorical features : \" + str(len(categorical_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert Categorical to Numerical using Ridge Regression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def catridge(cat2num_train_df,cat2num_test_df,column):\n",
    "    \n",
    "    global train_df, test_df\n",
    "    \n",
    "    ridge_fold = Ridge(fit_intercept=True)\n",
    "\n",
    "    state = 1\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=False, random_state=state)\n",
    "    #train_cat_dummies['CatRidge'] = pd.Series(np.nan())\n",
    "\n",
    "    fold = 0\n",
    "    \n",
    "    X_train = pd.get_dummies(train_df[[column]])\n",
    "    X_test = pd.get_dummies(test_df[[column]])\n",
    "    feat_intersect = list(set.intersection(set(X_train.columns.values),set(X_test.columns.values)))\n",
    "    X_train = X_train[feat_intersect]\n",
    "    X_test  = X_test[feat_intersect]\n",
    "    y_train = label_df['SalePrice']\n",
    "\n",
    "    ## Methodology\n",
    "    # For training set, the model fit for the other K-1 partitions will be used for prediction\n",
    "    # For test set, the mean of the predictions for the K models\n",
    "    CatRidge_train = np.zeros(y_train.shape[0])\n",
    "    CatRidge_test = np.zeros((X_test.shape[0],skf.get_n_splits()))\n",
    "\n",
    "    for train_index, test_index in skf.split(X_train,y_train):\n",
    "        X_train_fold  = X_train.iloc[train_index,:]\n",
    "        X_test_fold   = X_test.iloc[test_index,:]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        ridge_fold.fit(X_train_fold, y_train_fold)\n",
    "        CatRidge_train[test_index] = ridge_fold.predict(X_test_fold)\n",
    "        CatRidge_test[:,fold] = ridge_fold.predict(X_test)\n",
    "        fold = fold + 1\n",
    "        #print(\"Fold = %d, Score = %f\"% (fold, ridge_fold.score(X_test_fold,y_test_fold)))\n",
    "    \n",
    "    cat2num_train_df[column+'_ridge'] = pd.Series(CatRidge_train)\n",
    "    cat2num_test_df[column+'_ridge'] = np.mean(CatRidge_test,axis=1)\n",
    "    \n",
    "    \n",
    "    if skew(CatRidge_train) > 0.75:\n",
    "        cat2num_train_df[column+'_ridge'] = np.log1p(cat2num_train_df[column+'_ridge'])\n",
    "        \n",
    "    if skew(cat2num_test_df[column+'_ridge']) > 0.75:\n",
    "        cat2num_train_df[column+'_ridge'] = np.log1p(cat2num_train_df[column+'_ridge'])\n",
    "    \n",
    "    return cat2num_train_df,cat2num_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical features using one-hot encoding.\n",
    "def onehot(cat2num_train_df, cat2num_test_df, column):\n",
    "    \n",
    "    global train_df, test_df\n",
    "    \n",
    "    dummies_train = pd.get_dummies(train_df[column], prefix=\"_\" + column)\n",
    "    dummies_test = pd.get_dummies(test_df[column], prefix=\"_\" + column)\n",
    "\n",
    "    return cat2num_train_df.join(dummies_train), cat2num_test_df.join(dummies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical variables using Average All but One Encoding\n",
    "def AvgAllButOne(cat2num_train_df, cat2num_test_df, column):\n",
    "    global train_df, test_df, label_df\n",
    "    \n",
    "    column_df = pd.concat([train_df[[column]], label_df],axis=1)\n",
    "\n",
    "    #For Training Data    \n",
    "    for index, row in column_df.iterrows():\n",
    "        category = row[column]\n",
    "        cat_df = column_df.loc[column_df[column]==category,[column,'SalePrice']]\n",
    "        cat_len = cat_df.shape[0]\n",
    "\n",
    "        if(cat_len == 1):\n",
    "            cat2num_train_df.loc[index, column + '_aabo'] = row['SalePrice']\n",
    "        elif(cat_len > 1):\n",
    "            cat2num_train_df.loc[index, column + '_aabo'] = (np.sum(cat_df['SalePrice']) - row['SalePrice']) / (cat_len-1)    \n",
    "\n",
    "    #For Test data\n",
    "    column_grps = column_df[[column,'SalePrice']].groupby(column).agg('mean')\n",
    "    cat2num_test_df[column] = test_df[column]\n",
    "    #print(column_grps)\n",
    "    for category in column_grps.index:\n",
    "        cat2num_test_df.loc[cat2num_test_df[column]==category,column + '_aabo'] = column_grps.loc[category,'SalePrice']\n",
    "    \n",
    "    cat2num_test_df.drop(column,axis=1,inplace=True)\n",
    "    \n",
    "    return cat2num_train_df,cat2num_test_df\n",
    "\n",
    "    #train_cat.loc[train_cat[main_col] == category, main_col + '_freq'] = np.sum(train_cat_dummies[column])/train_cat_dummies.shape[0]\n",
    "    #test_cat.loc[test_cat[main_col] == category, main_col + '_freq'] = np.sum(train_cat_dummies[column])/train_cat_dummies.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert categorical features using one-hot encoding.\n",
    "def cat2num_main(cat2num_train_df, cat2num_test_df, column, fill_na_train,fill_na_test):\n",
    "    \n",
    "    global train_df, test_df\n",
    "    \n",
    "    print(\"FEATURE: %s\" %(column))\n",
    "    \n",
    "    if fill_na_train is not None:\n",
    "        train_df[column].fillna(fill_na_train, inplace=True)\n",
    "    \n",
    "    if fill_na_test is not None:\n",
    "        test_df[column].fillna(fill_na_test, inplace=True)\n",
    "        \n",
    "    # Ridge Regression\n",
    "    cat2num_train_df, cat2num_test_df = catridge(cat2num_train_df,cat2num_test_df,column)\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    cat2num_train_df, cat2num_test_df = onehot(cat2num_train_df,cat2num_test_df,column)\n",
    "    \n",
    "    # Average All But One\n",
    "    cat2num_train_df, cat2num_test_df = AvgAllButOne(cat2num_train_df,cat2num_test_df,column)\n",
    "\n",
    "    return cat2num_train_df, cat2num_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: MSSubClass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "cat2num_train_df = pd.DataFrame(index=train_df.index)\n",
    "cat2num_test_df  = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"MSSubClass\", None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: MSZoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: LotConfig\n",
      "FEATURE: Neighborhood\n",
      "FEATURE: Condition1\n",
      "FEATURE: BldgType\n",
      "FEATURE: HouseStyle\n",
      "FEATURE: RoofStyle\n",
      "FEATURE: Exterior1st\n",
      "FEATURE: Exterior2nd\n",
      "FEATURE: Foundation\n",
      "FEATURE: SaleType\n",
      "FEATURE: SaleCondition\n"
     ]
    }
   ],
   "source": [
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"MSZoning\", \"RL\", \"RL\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"LotConfig\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Neighborhood\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"Condition1\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"BldgType\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"HouseStyle\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"RoofStyle\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Exterior1st\", \"VinylSd\", \"VinylSd\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Exterior2nd\", \"VinylSd\", \"VinylSd\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"Foundation\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"SaleType\", \"WD\", \"WD\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"SaleCondition\", \"Normal\", \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: MasVnrType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: LotShape\n",
      "FEATURE: LandContour\n",
      "FEATURE: LandSlope\n",
      "FEATURE: Electrical\n",
      "FEATURE: GarageType\n",
      "FEATURE: PavedDrive\n",
      "FEATURE: MiscFeature\n",
      "FEATURE: Street\n",
      "FEATURE: Alley\n",
      "FEATURE: Condition2\n",
      "FEATURE: RoofMatl\n",
      "FEATURE: Heating\n"
     ]
    }
   ],
   "source": [
    "# Fill in missing MasVnrType for rows that do have a MasVnrArea.\n",
    "idx = (train_df[\"MasVnrArea\"] != 0) & ((train_df[\"MasVnrType\"] == \"None\") | (train_df[\"MasVnrType\"].isnull()))\n",
    "train_df.loc[idx, \"MasVnrType\"] = \"BrkFace\"\n",
    "idx = (test_df[\"MasVnrArea\"] != 0) & ((test_df[\"MasVnrType\"] == \"None\") | (test_df[\"MasVnrType\"].isnull()))\n",
    "test_df.loc[idx, \"MasVnrType\"] = \"BrkFace\"\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df, cat2num_test_df, \"MasVnrType\", \"None\", \"None\")\n",
    "\n",
    "# Also add the booleans from calc_df as dummy variables.\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"LotShape\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"LandContour\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"LandSlope\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Electrical\", \"SBrkr\", \"SBrkr\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"GarageType\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"PavedDrive\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"MiscFeature\", \"None\", \"None\")\n",
    "\n",
    "# Features we can probably ignore (but want to include anyway to see\n",
    "# if they make any positive difference).\n",
    "# Definitely ignoring Utilities: all records are \"AllPub\", except for\n",
    "# one \"NoSeWa\" in the train set and 2 NA in the test set.\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"Street\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Alley\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Condition2\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"RoofMatl\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"Heating\", None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: ExterQual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: ExterCond\n",
      "FEATURE: BsmtQual\n",
      "FEATURE: BsmtCond\n",
      "FEATURE: HeatingQC\n",
      "FEATURE: KitchenQual\n",
      "FEATURE: FireplaceQu\n",
      "FEATURE: GarageQual\n",
      "FEATURE: GarageCond\n",
      "FEATURE: PoolQC\n",
      "FEATURE: BsmtExposure\n",
      "FEATURE: BsmtFinType1\n",
      "FEATURE: BsmtFinType2\n",
      "FEATURE: Functional\n",
      "FEATURE: GarageFinish\n",
      "FEATURE: Fence\n",
      "FEATURE: MoSold\n",
      "FEATURE: GarageYrBltBin\n",
      "FEATURE: YearBuiltBin\n",
      "FEATURE: YearRemodAddBin\n"
     ]
    }
   ],
   "source": [
    "# I have these as numerical variables too.\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"ExterQual\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"ExterCond\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"BsmtQual\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"BsmtCond\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"HeatingQC\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"KitchenQual\", \"TA\", \"TA\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"FireplaceQu\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"GarageQual\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"GarageCond\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"PoolQC\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"BsmtExposure\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"BsmtFinType1\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"BsmtFinType2\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Functional\", \"Typ\", \"Typ\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"GarageFinish\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"Fence\", \"None\", \"None\")\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"MoSold\", None, None)\n",
    "\n",
    "# Divide up the years between 1871 and 2010 in slices of 20 years.\n",
    "year_map = pd.concat(pd.Series(\"YearBin\" + str(i+1), index=range(1871+i*20,1891+i*20)) for i in range(0, 7))\n",
    "\n",
    "train_df[\"GarageYrBltBin\"] = train_df.GarageYrBlt.map(year_map)\n",
    "train_df[\"GarageYrBltBin\"].fillna(\"NoGarage\", inplace=True)\n",
    "train_df[\"YearBuiltBin\"] = train_df.YearBuilt.map(year_map)\n",
    "train_df[\"YearRemodAddBin\"] = train_df.YearRemodAdd.map(year_map)\n",
    "\n",
    "test_df[\"GarageYrBltBin\"] = test_df.GarageYrBlt.map(year_map)\n",
    "test_df[\"GarageYrBltBin\"].fillna(\"NoGarage\", inplace=True)\n",
    "test_df[\"YearBuiltBin\"] = test_df.YearBuilt.map(year_map)\n",
    "test_df[\"YearRemodAddBin\"] = test_df.YearRemodAdd.map(year_map)\n",
    "\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"GarageYrBltBin\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"YearBuiltBin\", None, None)\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df,  \"YearRemodAddBin\", None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE: NeighborhoodBin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# Encode Neighborhood Bin Trian\n",
    "\n",
    "train_df[\"NeighborhoodBin\"] = neighborhood_bin_train[\"NeighborhoodBin\"]\n",
    "test_df[\"NeighborhoodBin\"] = neighborhood_bin_test[\"NeighborhoodBin\"]\n",
    "\n",
    "cat2num_train_df,cat2num_test_df = cat2num_main(cat2num_train_df,cat2num_test_df, \"NeighborhoodBin\", None, None)\n",
    "train_df_munged = train_df_munged.join(cat2num_train_df)\n",
    "test_df_munged = test_df_munged.join(cat2num_test_df)\n",
    "\n",
    "# Retain only columns appearing in both training and test munged data\n",
    "feat_intersect = list(set.intersection(set(train_df_munged.columns.values),set(test_df_munged.columns.values)))\n",
    "train_df_munged = train_df_munged[feat_intersect]\n",
    "test_df_munged  = test_df_munged[feat_intersect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df_munged['GarageYrBlt'] = test_df_munged['GarageYrBlt'].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([], dtype='object'), Index([], dtype='object'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_munged.select_dtypes(include=[\"object\"]).columns, test_df_munged.select_dtypes(include=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_munged Null values:\n",
      "BsmtQual_ridge           4\n",
      "MasVnrType_ridge         4\n",
      "Foundation_ridge         4\n",
      "MSZoning_ridge           4\n",
      "SaleCondition_ridge      4\n",
      "ExterCond_ridge          4\n",
      "NeighborhoodBin_ridge    4\n",
      "GarageFinish_ridge       4\n",
      "BsmtExposure_ridge       4\n",
      "GarageYrBltBin_ridge     4\n",
      "GarageType_ridge         4\n",
      "LotShape_ridge           4\n",
      "PoolQC_ridge             4\n",
      "Fence_ridge              4\n",
      "LandContour_ridge        4\n",
      "BsmtFinType1_ridge       4\n",
      "LandSlope_ridge          4\n",
      "RoofMatl_ridge           4\n",
      "Functional_ridge         4\n",
      "YearRemodAddBin_ridge    4\n",
      "Electrical_ridge         4\n",
      "Street_ridge             4\n",
      "Neighborhood_ridge       4\n",
      "BsmtFinType2_ridge       4\n",
      "BldgType_ridge           4\n",
      "MiscFeature_ridge        4\n",
      "BsmtCond_ridge           4\n",
      "YearBuiltBin_ridge       4\n",
      "Exterior1st_ridge        4\n",
      "Condition1_ridge         4\n",
      "HeatingQC_ridge          4\n",
      "KitchenQual_ridge        4\n",
      "Alley_ridge              4\n",
      "Condition2_ridge         4\n",
      "HouseStyle_ridge         4\n",
      "FireplaceQu_ridge        4\n",
      "ExterQual_ridge          4\n",
      "GarageCond_ridge         4\n",
      "GarageQual_ridge         4\n",
      "MoSold_ridge             4\n",
      "RoofStyle_ridge          4\n",
      "SaleType_ridge           4\n",
      "LotConfig_ridge          4\n",
      "Exterior2nd_ridge        4\n",
      "PavedDrive_ridge         4\n",
      "MSSubClass_ridge         4\n",
      "Heating_ridge            4\n",
      "dtype: int64\n",
      "test_df_munged Null values:\n",
      "MSSubClass_aabo    1\n",
      "dtype: int64\n",
      "train_df_munged Null values:\n",
      "Series([], dtype: float64)\n",
      "test_df_munged Null values:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_df_munged Null values:\")\n",
    "print(np.sum(train_df_munged.loc[:,train_df_munged.isnull().any(axis=0)==True].isnull()))\n",
    "\n",
    "print(\"test_df_munged Null values:\")\n",
    "print(np.sum(test_df_munged.loc[:,test_df_munged.isnull().any(axis=0)==True].isnull()))\n",
    "\n",
    "train_df_munged = train_df_munged.fillna(pd.concat([train_df_munged]).median())\n",
    "test_df_munged = test_df_munged.fillna(pd.concat([train_df_munged]).median())\n",
    "\n",
    "print(\"train_df_munged Null values:\")\n",
    "print(np.sum(train_df_munged.loc[:,train_df_munged.isnull().any(axis=0)==True].isnull()))\n",
    "\n",
    "print(\"test_df_munged Null values:\")\n",
    "print(np.sum(test_df_munged.loc[:,test_df_munged.isnull().any(axis=0)==True].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional processing: scale the data.   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_df_munged = scaler.fit_transform(train_df_munged)\n",
    "test_df_munged = scaler.transform(test_df_munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df_munged.shape, test_df_munged.shape,label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    }
   ],
   "source": [
    "## Xgboost gridsearch\n",
    "import sklearn\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "xtreme_forest = xgb.XGBRegressor()\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4],\n",
    "                 'n_estimators':[1000],\n",
    "                 'min_child_weight': [1,2,3],\n",
    "                 'learning_rate':[0.005,0.01,0.05],\n",
    "                 'colsample_bytree':[0.1,0.3,0.5],\n",
    "                 'subsample': [0.1,0.2,0.5],\n",
    "                 'silent':[1],\n",
    "                 }\n",
    "\n",
    "cross_validation = sklearn.cross_validation.StratifiedKFold(np.array(label_df['SalePrice']), n_folds=5)\n",
    "\n",
    "grid_search_xgboost = GridSearchCV(xtreme_forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           scoring= \"neg_mean_squared_error\",\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search_xgboost.fit(train_df_munged, label_df)\n",
    "\n",
    "print('Best score: {}'.format(grid_search_xgboost.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search_xgboost.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XGBoost -- I did some \"manual\" cross-validation here but should really find\n",
    "# these hyperparameters using CV. ;-)\n",
    "\n",
    "xgb_regr = xgb.XGBRegressor(\n",
    "                 colsample_bytree=0.2,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=4,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=7200,                                                                  \n",
    "                 reg_alpha=0.9,\n",
    "                 reg_lambda=0.6,\n",
    "                 subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1)\n",
    "\n",
    "xgb_regr.fit(train_df_munged, label_df)\n",
    "\n",
    "# Run prediction on training set to get a rough idea of how well it does.\n",
    "y_train_pred_xgb = xgb_regr.predict(train_df_munged)\n",
    "y_test = label_df\n",
    "print(\"XGBoost score on training set: \", rmse(y_test, y_train_pred_xgb))\n",
    "\n",
    "# Run prediction on the Kaggle test set.\n",
    "y_test_pred_xgb = xgb_regr.predict(test_df_munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_xgboost.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasso Grid Search\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_grid = Lasso()\n",
    "\n",
    "parameter_grid = {\n",
    "                 'alpha': [0.001,0.01,0.1,0.5,1],\n",
    "                 'fit_intercept': [True, False],\n",
    "                 'normalize': [True,False]\n",
    "                 }\n",
    "\n",
    "cross_validation = sklearn.cross_validation.StratifiedKFold(np.array(label_df['SalePrice']), n_folds=10)\n",
    "\n",
    "grid_search_lasso = GridSearchCV(lasso_grid,\n",
    "                           param_grid=parameter_grid,\n",
    "                           scoring= \"neg_mean_squared_error\",\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search_lasso.fit(train_df_munged, label_df)\n",
    "\n",
    "print('Best score: {}'.format(grid_search_lasso.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search_lasso.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_lasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred_lasso = grid_search_lasso.best_estimator_.predict(train_df_munged)\n",
    "print(\"Elastic Net score on training set: \", rmse(label_df,y_train_pred_elastic))\n",
    "y_test_pred_lasso = grid_search_lasso.best_estimator_.predict(test_df_munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# I found this best alpha through cross-validation.\n",
    "best_alpha = 0.00099\n",
    "\n",
    "lasso_regr = Lasso(alpha=best_alpha, max_iter=50000)\n",
    "lasso_regr.fit(train_df_munged, label_df)\n",
    "\n",
    "# Run prediction on training set to get a rough idea of how well it does.\n",
    "y_train_pred_lasso = lasso_regr.predict(train_df_munged)\n",
    "y_test = label_df\n",
    "print(\"Lasso score on training set: \", rmse(y_test, y_train_pred_lasso))\n",
    "\n",
    "# Run prediction on the Kaggle test set.\n",
    "y_test_pred_lasso = lasso_regr.predict(test_df_munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests don't perform well with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extra Trees Regressor\n",
    "\n",
    "et_regr = ExtraTreesRegressor(n_estimators=5000, max_depth=8, max_features='sqrt',n_jobs=-1)\n",
    "et_regr.fit(train_df_munged, label_df)\n",
    "\n",
    "# Run prediction on training set to get a rough idea of how well it does.\n",
    "y_pred = et_regr.predict(train_df_munged)\n",
    "y_test = label_df\n",
    "print(\"Extra Trees Regressor score on training set: \", rmse(y_test, y_pred))\n",
    "\n",
    "# Run prediction on the Kaggle test set.\n",
    "y_pred_et = et_regr.predict(test_df_munged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees Regressor also no where in the range of performance of Lasso XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Kernel Ridge GridSearch\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "kridge_grid = KernelRidge()\n",
    "\n",
    "parameter_grid = {\n",
    "                 'alpha': [0.0001,0.001,0.01,0.1,1,10,30,60],\n",
    "                 'degree': [1,2,3,4],\n",
    "                 'kernel': ['polynomial']\n",
    "                 #'n_estimators': [200,210,240,250],\n",
    "                 #'min_child_weight': [1,2,3,4]\n",
    "                 }\n",
    "\n",
    "cross_validation = sklearn.cross_validation.StratifiedKFold(np.array(label_df['SalePrice']), n_folds=10)\n",
    "\n",
    "grid_search_kridge = GridSearchCV(kridge_grid,\n",
    "                           param_grid=parameter_grid,\n",
    "                           scoring= \"neg_mean_squared_error\",\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search_kridge.fit(train_df_munged, label_df)\n",
    "\n",
    "print('Best score: {}'.format(grid_search_kridge.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search_kridge.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred_kridge = grid_search_kridge.best_estimator_.predict(train_df_munged)\n",
    "print(\"Kernel Ridge score on training set: \", rmse(label_df,y_train_pred_kridge))\n",
    "y_test_pred_kridge = grid_search_kridge.best_estimator_.predict(test_df_munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred_kridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something wrong with test predictions using Kernel Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_grid = GradientBoostingRegressor(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,6,8],\n",
    "                 'n_estimators': [5000],\n",
    "                 'min_samples_split':[5,10,15,20]\n",
    "                 }\n",
    "\n",
    "cross_validation = sklearn.cross_validation.StratifiedKFold(label_df['SalePrice'], n_folds=5)\n",
    "\n",
    "grid_search_gbm = GridSearchCV(gbm_grid,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search_gbm.fit(train_df_munged, label_df)\n",
    "\n",
    "print('Best score: {}'.format(grid_search_gbm.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search_gbm.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_pred_gbm = grid_search_gbm.best_estimator_.predict(train_df_munged)\n",
    "print(\"GBM score on training set: \", rmse(label_df,y_train_pred_gbm))\n",
    "y_test_pred_gbm = grid_search_gbm.best_estimator_.predict(test_df_munged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred_kridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending using Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Analyzing the Weighting performances\n",
    "## XGboost + Lasso + Kernel Ridge + GBM\n",
    "rmse_arr = np.empty([5,5,5,5])\n",
    "\n",
    "for wt_xgb in np.arange(0,5):\n",
    "    for wt_lasso in np.arange(0,5):\n",
    "        for wt_kridge in np.arange(0,5):\n",
    "            for wt_gbm in np.arange(0,5):\n",
    "                if(wt_lasso + wt_kridge + wt_xgb + wt_gbm == 0):\n",
    "                    rmse_arr[wt_xgb,wt_lasso,wt_kridge,wt_gbm] = 0.1\n",
    "                    continue\n",
    "                #for wt_gbm in np.arange(0,4):\n",
    "                y_pred_avg = (wt_xgb*np.ravel(y_train_pred_xgb) + wt_lasso*np.ravel(y_train_pred_lasso) + wt_kridge*np.ravel(y_train_pred_kridge) + wt_gbm*np.ravel(y_train_pred_gbm))\n",
    "                y_pred_avg = y_pred_avg / (wt_xgb + wt_lasso + wt_kridge+wt_gbm)\n",
    "                if rmse(label_df,y_pred_avg) < 0.0005:\n",
    "                    rmse_arr[wt_xgb,wt_lasso,wt_kridge,wt_gbm] = 0.1\n",
    "                else:    \n",
    "                    rmse_arr[wt_xgb,wt_lasso,wt_kridge,wt_gbm] = rmse(label_df,y_pred_avg)\n",
    "                print(\"RMSE Training Error for ::wt_xgb=%s, wt_lasso=%s, wt_kridge=%s, wt_gbm=%s:: = %s\\n\" %(str(wt_xgb), str(wt_lasso), str(wt_kridge), str(wt_gbm),str(1000*rmse(label_df,y_pred_avg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Lasso + Kernel Ridge Weight Analysis\n",
    "rmse_arr = np.zeros([5,5])\n",
    "\n",
    "for wt_lasso in np.arange(0,5):\n",
    "    for wt_kridge in np.arange(0,5):\n",
    "        if(wt_lasso + wt_kridge == 0):\n",
    "            rmse_arr[wt_lasso,wt_kridge] = 0.1\n",
    "            continue\n",
    "        #for wt_gbm in np.arange(0,4):\n",
    "        y_pred_avg = (wt_lasso*np.ravel(y_train_pred_lasso) + wt_kridge*np.ravel(y_train_pred_kridge))\n",
    "        y_pred_avg = y_pred_avg / (wt_lasso + wt_kridge)\n",
    "        rmse_arr[wt_lasso,wt_kridge] = rmse(label_df,y_pred_avg)\n",
    "        print(\"RMSE Training Error for ::wt_lasso=%s, wt_kridge=%s:: = %s\\n\" %(str(wt_lasso), str(wt_kridge),  str(1000*rmse(label_df,y_pred_avg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Analyzing the error\n",
    "ravel_rmse = 1000*np.ravel(rmse_arr)\n",
    "ravel_rmse = ravel_rmse[ravel_rmse>1]\n",
    "#sorted_rmse = sorted_rmse[sorted_rmse<100000]\n",
    "print(np.max(ravel_rmse))\n",
    "print(np.min(ravel_rmse))\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.plot(ravel_rmse)#, np.linspace(0,1,sorted_rmse.size))\n",
    "#plt.xlim([0,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "Training error:\n",
    "\n",
    "1) decreases with weight increase of XGBoost\n",
    "\n",
    "2) increases with weight increase of Lasso\n",
    "\n",
    "3) decreases with weight increase of Kernel Ridge\n",
    "\n",
    "4) increases with weight increase of Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(rmse_arr.shape)\n",
    "\n",
    "print(\"Min = \", np.min(rmse_arr))\n",
    "print(np.where(rmse_arr == np.min(rmse_arr)))\n",
    "\n",
    "print(\"Max = \", np.max(rmse_arr))\n",
    "print(np.where(rmse_arr == np.max(rmse_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_final = (1*np.ravel(y_test_pred_xgb) + 0*np.ravel(y_test_pred_kridge) + 1*np.ravel(y_test_pred_gbm))/2\n",
    "y_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending using Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(attempt, actual, epsilon=1.0e-15):\n",
    "    \"\"\"Logloss, i.e. the score of the bioresponse competition.\n",
    "    \"\"\"\n",
    "    attempt = np.clip(attempt, epsilon, 1.0-epsilon)\n",
    "    return - np.mean(actual * np.log(attempt) +\n",
    "                     (1.0 - actual) * np.log(1.0 - attempt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)  # seed to shuffle the train set\n",
    "\n",
    "n_folds = 10\n",
    "verbose = True\n",
    "shuffle = False\n",
    "\n",
    "X_ens = np.array(train_df_munged)\n",
    "y_ens = np.array(label_df['SalePrice'])\n",
    "X_submission = np.array(test_df_munged)\n",
    "\n",
    "if shuffle:\n",
    "    idx = np.random.permutation(y.size)\n",
    "    X_ens = train_df_munged[idx]\n",
    "    y_ens = targets_munged[idx]\n",
    "\n",
    "skf = list(StratifiedKFold(y_ens, n_folds))\n",
    "\n",
    "clfs = [lasso_regr,\n",
    "        xgb_regr,\n",
    "        #RandomForestRegressor(n_estimators=5000, max_depth=4, max_features='sqrt',n_jobs=-1),\n",
    "        #ExtraTreesRegressor(n_estimators=5000, max_depth=4,n_jobs=-1),\n",
    "        GradientBoostingRegressor(learning_rate=0.05, subsample=0.5, max_features='sqrt',max_depth=4, n_estimators=5000),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating train and test sets for blending\n",
    "\n",
    "dataset_blend_train = np.zeros((X_ens.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(clfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j, clf in enumerate(clfs):\n",
    "    print(j, clf)\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "    for i, (train_curr, test_curr) in enumerate(skf):\n",
    "        print(\"Fold\", i)\n",
    "        X_train = X_ens[train_curr]\n",
    "        y_train = y_ens[train_curr]\n",
    "        X_test = X_ens[test_curr]\n",
    "        y_test = y_ens[test_curr]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict(X_test)\n",
    "        dataset_blend_train[test_curr, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict(X_submission)\n",
    "        dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "print (\"Blending over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_final = np.mean(dataset_blend_test,axis=1)\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "dd = KernelRidge()\n",
    "dd.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "linear_grid = LinearRegression()\n",
    "\n",
    "parameter_grid = {\n",
    "                 'fit_intercept': [True,False],\n",
    "                 'normalize':[True,False]\n",
    "                 #'n_estimators': [200,210,240,250],\n",
    "                 #'min_child_weight': [1,2,3,4]\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(np.array(label_df['SalePrice']), n_folds=5)\n",
    "\n",
    "grid_search_linear = GridSearchCV(linear_grid,\n",
    "                           param_grid=parameter_grid,\n",
    "                           scoring= \"r2\",\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search_linear.fit(dataset_blend_train, y_ens)\n",
    "\n",
    "print('Best score: {}'.format(grid_search_linear.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search_linear.best_params_))\n",
    "\n",
    "#clf.fit(dataset_blend_train, y_ens)\n",
    "#y_final = clf.predict(dataset_blend_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "kridge_grid = KernelRidge()\n",
    "\n",
    "parameter_grid = {\n",
    "                 'alpha': [0.0001,0.001,0.01,0.1],\n",
    "                 'degree': [1,2,3,4],\n",
    "                 'kernel': ['polynomial']\n",
    "                 #'n_estimators': [200,210,240,250],\n",
    "                 #'min_child_weight': [1,2,3,4]\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(np.array(label_df['SalePrice']), n_folds=10)\n",
    "\n",
    "grid_search_kridge = GridSearchCV(kridge_grid,\n",
    "                           param_grid=parameter_grid,\n",
    "                           scoring= \"neg_mean_squared_error\",\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search_kridge.fit(dataset_blend_train, y_ens)\n",
    "\n",
    "print('Best score: {}'.format(grid_search_kridge.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search_kridge.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search_kridge.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "ensemble_clfs_0106 = clfs\n",
    "\n",
    "with open('0106_objs.pckl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([train_df_munged,test_df_munged,ensemble_clfs_0106,dataset_blend_test,dataset_blend_train], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.exp(y_final)\n",
    "\n",
    "# Final Conversion.\n",
    "output_file = 'new_feat_xgboost_gbm_1_1'\n",
    "final_file = '0112_'+ output_file +'.csv'\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred, index=test_df[\"Id\"], columns=[\"SalePrice\"])\n",
    "pred_df.shape\n",
    "pred_df.to_csv(path+final_file, header=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### We can improve it by CV and stacking   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
