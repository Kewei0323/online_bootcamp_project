{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random state\n",
    "state = 1\n",
    "\n",
    "# load boston dataset\n",
    "boston = load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# outer cross-validation\n",
    "outer = cross_validation.KFold(len(y), n_folds=3, shuffle=True, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter of 1 fold: 1200\n",
      "Best parameter of 2 fold: 1000\n",
      "Best parameter of 3 fold: 1200\n"
     ]
    }
   ],
   "source": [
    "outer_scores = []\n",
    "for fold, (train_index_outer, test_index_outer) in enumerate(outer):\n",
    "    X_train_outer, X_test_outer = X[train_index_outer], X[test_index_outer]\n",
    "    y_train_outer, y_test_outer = y[train_index_outer], y[test_index_outer]\n",
    "\n",
    "    inner_mean_scores = []\n",
    "\n",
    "    # define explored parameter space.\n",
    "    # procedure below should be equal to GridSearchCV\n",
    "    tuned_parameter = [1000, 1100, 1200]\n",
    "    for param in tuned_parameter:\n",
    "\n",
    "        inner_scores = []\n",
    "\n",
    "        # inner cross-validation\n",
    "        inner = cross_validation.KFold(len(X_train_outer), n_folds=3, shuffle=True, random_state=state)\n",
    "        for train_index_inner, test_index_inner in inner:\n",
    "            # split the training data of outer CV\n",
    "            X_train_inner, X_test_inner = X_train_outer[train_index_inner], X_train_outer[test_index_inner]\n",
    "            y_train_inner, y_test_inner = y_train_outer[train_index_inner], y_train_outer[test_index_inner]\n",
    "\n",
    "            # fit extremely randomized trees regressor to training data of inner CV\n",
    "            clf = ensemble.ExtraTreesRegressor(param, n_jobs=-1, random_state=1)\n",
    "            clf.fit(X_train_inner, y_train_inner)\n",
    "            inner_scores.append(clf.score(X_test_inner, y_test_inner))\n",
    "\n",
    "        # calculate mean score for inner folds\n",
    "        inner_mean_scores.append(np.mean(inner_scores))\n",
    "\n",
    "    # get maximum score index\n",
    "    index, value = max(enumerate(inner_mean_scores), key=operator.itemgetter(1))\n",
    "\n",
    "    print('Best parameter of %i fold: %i' % (fold + 1, tuned_parameter[index]))\n",
    "\n",
    "    # fit the selected model to the training set of outer CV\n",
    "    # for prediction error estimation\n",
    "    clf2 = ensemble.ExtraTreesRegressor(tuned_parameter[index], n_jobs=-1, random_state=1)\n",
    "    clf2.fit(X_train_outer, y_train_outer)\n",
    "    outer_scores.append(clf2.score(X_test_outer, y_test_outer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the prediction error estimate produced by nested CV\n",
    "print('Unbiased prediction error: %.4f' % (np.mean(outer_scores)))\n",
    "\n",
    "# finally, fit the selected model to the whole dataset\n",
    "clf3 = ensemble.ExtraTreesRegressor(tuned_parameter[index], n_jobs=-1, random_state=1)\n",
    "clf3.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Nested Cross-Validation\n",
    "\n",
    "Nested CV is required for a model's unbiased error estimation. We can compare the score of different models in this manner. Using this information, we can then perform a separate K-fold CV loop for parameter tuning of the selected models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
